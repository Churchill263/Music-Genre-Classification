# -*- coding: utf-8 -*-
"""Final Intro to AI Final Project G.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t9wh6vS7U4zHTU0SBiFthMwN6yctty1m
"""

import numpy as np
import pandas as pd
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
import os
import math
import pickle
import random
import operator
import IPython.display as ipd
import librosa
import librosa.display
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from tensorflow.keras.callbacks import ModelCheckpoint
import time
from datetime import datetime

audio_set_path = '/content/drive/MyDrive/genres_original'
metadata = pd.read_csv('/content/drive/MyDrive/features_30_sec.csv')

metadata.head()

def features_extractor(file):
  audio, sample_rate = librosa.load(file_name, res_type= 'kaiser_fast')
  mfccs_features = librosa.feature.mfcc(y = audio, sr = sample_rate, n_mfcc = 40)
  mfccs_scaled_features = np.mean(mfccs_features. T, axis = 0)

  return mfccs_scaled_features

extracted_features = []
for index_num, row in tqdm(metadata.iterrows()):
  try:
    class_labels = row['label']
    file_name = os.path.join(os.path.abspath(audio_set_path), class_labels+'/',str(row['filename']))
    data = features_extractor(file_name)
    extracted_features.append([data,class_labels])
  except Exception as e:
    print(f'Error: {e}')
    continue

extracted_features_df = pd.DataFrame(extracted_features, columns = ['feature','class'])
extracted_features_df.head()

extracted_features_df['class'].value_counts()

X = np.array(extracted_features_df['feature'].tolist())
y = np.array(extracted_features_df['class'].tolist())

X.shape

encoder = LabelEncoder()
y = to_categorical(encoder.fit_transform(y))

y.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

num_labels = y.shape[1]

num_labels

model = Sequential()
model.add(Dense(1024, input_shape=(40,), activation = "relu"))
model.add(Dropout (0.3))
model.add(Dense (512, activation="relu"))
model.add(Dropout (0.3))
model.add(Dense (256, activation="relu"))
model.add(Dropout (0.3))
model.add(Dense (128, activation="relu"))
model.add(Dropout (0.3))
model.add(Dense (64, activation="relu"))
model.add(Dropout (0.3))
model.add(Dense (32, activation="relu"))
model.add(Dropout (0.3))
###final layer
model. add (Dense(num_labels, activation="softmax"))

model.summary()

model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')

t = time.localtime()
current_time = time.strftime('%H:%M:%S', t)

num_epochs = 100
num_batch_size = 32

checkpointer = ModelCheckpoint(filepath=f'saved_models/audio_classification_{current_time}.hdf5', verbose = 1, save_best_only = True)

start = datetime.now()

history = model.fit(X_train, y_train, batch_size = num_batch_size, epochs = num_epochs, validation_data= (X_test, y_test), callbacks = [checkpointer], verbose = 1)

duration = datetime.now() - start
print('Training completed in: ', duration)

model.evaluate(X_test, y_test, verbose = 0)

pip freeze | grep 'numpy\|pandas\|scipy\|matplotlib\|librosa\|tensorflow\|scikit-learn\|IPython' > requirements.txt

encoder_filename = 'encoder.pkl'
with open(encoder_filename, 'wb') as encoder_file:
    pickle.dump({'encoder': encoder},encoder_file)

